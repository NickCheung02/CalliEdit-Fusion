{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "def get_supported_chars(font_path):\n",
    "    # 加载字体文件\n",
    "    font = TTFont(font_path)\n",
    "    \n",
    "    # 获取字体文件的字符映射表\n",
    "    cmap = font['cmap']\n",
    "    \n",
    "    # 集合来存储所有支持的字符\n",
    "    supported_chars = set()\n",
    "    \n",
    "    # 遍历字符映射表的每个子表\n",
    "    for table in cmap.tables:\n",
    "        # 添加支持的字符到集合中\n",
    "        supported_chars.update([chr(c) for c in table.cmap.keys()])\n",
    "    \n",
    "    return supported_chars\n",
    "\n",
    "char_table =  get_supported_chars('xxxxxx/font/NotoSansHans-Medium.otf')\n",
    "\n",
    "print(len(char_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import urllib\n",
    "from PIL import Image,ImageFont,ImageDraw\n",
    "import cv2\n",
    "\n",
    "BASE_FONT = 'xxxxxx/font/NotoSansHans-Medium.otf'\n",
    "\n",
    "\n",
    "# for Pillow==10.3.0\n",
    "def pil_content_render(content, font_size, font_path, font_color=(0, 0, 0)):\n",
    "    # 初始化字体\n",
    "    font = ImageFont.truetype(font_path, size=font_size)\n",
    "    \n",
    "    # 获取文本尺寸\n",
    "    bbox = font.getbbox(content)\n",
    "        \n",
    "    # 创建适当大小的白底图像\n",
    "    image_size = (bbox[2], bbox[3])\n",
    "\n",
    "    ct_img = np.ones((image_size[1], image_size[0], 3), dtype=np.uint8) * 255\n",
    "    \n",
    "    # 转换为PIL图像\n",
    "    ct_img = Image.fromarray(ct_img)\n",
    "    draw = ImageDraw.Draw(ct_img)\n",
    "    \n",
    "    # 绘制文本\n",
    "    draw.text((0, 0), content, font=font, fill=font_color)\n",
    "    \n",
    "    # 转换为OpenCV格式\n",
    "    ct_img = cv2.cvtColor(np.asarray(ct_img), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return ct_img\n",
    "\n",
    "\n",
    "def synthesis_content_img(content, text_size):\n",
    "    st_h, st_w = text_size\n",
    "    bg_img = np.ones((st_h, st_w, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    global BASE_FONT # font path\n",
    "    \n",
    "    # 内容文本\n",
    "    ct_img = pil_content_render(content=content, \n",
    "                                font_size=st_h, \n",
    "                                font_path=BASE_FONT,\n",
    "                                font_color=(0,0,0))\n",
    "    \n",
    "    ct_h, ct_w, _ = ct_img.shape\n",
    "\n",
    "    # 不改变aspect ratios 缩放到 style img 能够容纳的长宽\n",
    "    new_w, new_h = ct_w, ct_h\n",
    "\n",
    "    if (ct_h>st_h) or (ct_w>st_w): \n",
    "        if (ct_h/ct_w) > (st_h/st_w):\n",
    "            new_h = st_h\n",
    "            new_w = int((st_h/ct_h) * ct_w) \n",
    "        else:\n",
    "            new_w = st_w\n",
    "            new_h = int((st_w/ct_w) * ct_h)\n",
    "\n",
    "    resized_ct_img = cv2.resize(ct_img,\n",
    "                                (new_w, new_h), \n",
    "                                interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # center paste\n",
    "    real_text_pos = [(st_w-new_w)//2, (st_h-new_h)//2, (st_w-new_w)//2+new_w, (st_h-new_h)//2+new_h]\n",
    "\n",
    "    bg_img[(st_h-new_h)//2 : (st_h-new_h)//2+new_h,\n",
    "            (st_w-new_w)//2 : (st_w-new_w)//2+new_w, :] = resized_ct_img\n",
    "\n",
    "    return bg_img, real_text_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "H = 48\n",
    "W = 48*2\n",
    "content_im, _ = synthesis_content_img('三', (H, W)) # 渲染文字，返回图片，白底黑字，需要自己试下\n",
    "content_im = content_im\n",
    "\n",
    "plt.imshow(content_im)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(content_im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict\n",
    "from model.recognizer import TextRecognizer, create_predictor\n",
    "\n",
    "import model.recognizer\n",
    "reload(model.recognizer)\n",
    "from model.recognizer import TextRecognizer, create_predictor\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "rec_model_dir = \"./ocr_weights/ppv3_rec.pth\"\n",
    "text_predictor = create_predictor(rec_model_dir).eval().to(device=device)\n",
    "orc_args = edict()\n",
    "orc_args.rec_image_shape = f\"3, {H}, {W}\"\n",
    "\n",
    "orc_args.rec_batch_num = 6\n",
    "orc_args.rec_char_dict_path = './ocr_recog/ppocr_keys_v1.txt'\n",
    "orc_args.use_fp16 = False\n",
    "cn_recognizer = TextRecognizer(orc_args, text_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# check image and feature shape\n",
    "\n",
    "content_im = torch.from_numpy(content_im).to(device=device).permute(2, 0, 1) / 127.5 - 1.0 \n",
    "print(content_im.shape)\n",
    "preds, preds_neck, preds_bc = cn_recognizer.pred_imglist([content_im, ], show_debug=False)\n",
    "print(preds_neck.shape)\n",
    "print(preds.shape)\n",
    "print(preds_bc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "char_table = list(char_table)\n",
    "char2feat_ocr = {}\n",
    "with torch.no_grad():\n",
    "    for char in tqdm(char_table):\n",
    "        try:\n",
    "            content_im, _ = synthesis_content_img(char, (H, W))\n",
    "        except Exception:\n",
    "            print(f'render error: {char}')\n",
    "            continue\n",
    "        \n",
    "        # to tensor\n",
    "        content_im = torch.from_numpy(content_im).to(device=device).permute(2, 0, 1) / 127.5 - 1.0 \n",
    "\n",
    "        # 这里需要下改recognizer.pred_imglist函数的返回值，来自anytext\n",
    "        preds, preds_neck, preds_bc = cn_recognizer.pred_imglist([content_im,], show_debug=False)\n",
    "\n",
    "        # decode\n",
    "        preds_all = preds.softmax(dim=-1) \n",
    "        pred = preds_all[0]\n",
    "        order, idx = cn_recognizer.decode(pred)\n",
    "        text = cn_recognizer.get_text(order)\n",
    "\n",
    "        # ocr feat\n",
    "        preds_neck = preds_neck[0]\n",
    "        preds = preds[0]\n",
    "        preds_bc = preds_bc[0]\n",
    "\n",
    "        # mean pooling\n",
    "        feat = torch.mean(preds_neck, dim=0)\n",
    "\n",
    "        char2feat_ocr[char] = feat.cpu().clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(char2feat_ocr, 'xxxxxx/char2feat_ocr.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
